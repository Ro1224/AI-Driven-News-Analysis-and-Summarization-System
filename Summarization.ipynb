{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11050513,"sourceType":"datasetVersion","datasetId":6884312}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\n\n# Load tokenizer and model directly from Hugging Face Hub\nmodel_name = \"facebook/bart-large-cnn\"\n\n# Load tokenizer and model\nbart_tokenizer = BartTokenizer.from_pretrained(model_name)\nbart_model = BartForConditionalGeneration.from_pretrained(model_name)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:53:11.385693Z","iopub.execute_input":"2025-03-17T12:53:11.385987Z","iopub.status.idle":"2025-03-17T12:53:42.443008Z","shell.execute_reply.started":"2025-03-17T12:53:11.385957Z","shell.execute_reply":"2025-03-17T12:53:42.442024Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"931c3c4b6d85492e835563c3b5c18802"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9c59f046b3847caaf061ea204b00517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc8bf8185d2464aab74c5ff676e4733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5e79c054434e29b219b42ff054d870"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f890c96d72c54ef1bc8dff7c495c3b1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63b4c5164572441ba3416de5fbf66b65"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import spacy\nimport subprocess\nimport os\n\n# Path to save spaCy models\nspacy_save_path = \"/kaggle/working/spacy_models\"\nos.makedirs(spacy_save_path, exist_ok=True)\n\n# List of spaCy models for supported languages\nspacy_models = [\n    \"en_core_web_sm\", \"de_core_news_sm\", \"fr_core_news_sm\", \"es_core_news_sm\",\n    \"it_core_news_sm\", \"nl_core_news_sm\", \"pt_core_news_sm\", \"el_core_news_sm\",\n    \"ru_core_news_sm\", \"zh_core_web_sm\", \"ja_core_news_sm\", \"ko_core_news_sm\"\n]\n\n# Download and save spaCy models\nfor model in spacy_models:\n    try:\n        spacy.load(model)\n    except:\n        print(f\"⏳ Downloading spaCy model: {model}\")\n        subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", model])\n        spacy.load(model).to_disk(f\"{spacy_save_path}/{model}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:53:42.443907Z","iopub.execute_input":"2025-03-17T12:53:42.444539Z","iopub.status.idle":"2025-03-17T12:55:44.682992Z","shell.execute_reply.started":"2025-03-17T12:53:42.444512Z","shell.execute_reply":"2025-03-17T12:55:44.682046Z"}},"outputs":[{"name":"stdout","text":"⏳ Downloading spaCy model: de_core_news_sm\n⏳ Downloading spaCy model: fr_core_news_sm\n⏳ Downloading spaCy model: es_core_news_sm\n⏳ Downloading spaCy model: it_core_news_sm\n⏳ Downloading spaCy model: nl_core_news_sm\n⏳ Downloading spaCy model: pt_core_news_sm\n⏳ Downloading spaCy model: el_core_news_sm\n⏳ Downloading spaCy model: ru_core_news_sm\n⏳ Downloading spaCy model: zh_core_web_sm\n⏳ Downloading spaCy model: ja_core_news_sm\n⏳ Downloading spaCy model: ko_core_news_sm\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install stanza\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:55:44.683924Z","iopub.execute_input":"2025-03-17T12:55:44.684515Z","iopub.status.idle":"2025-03-17T12:55:49.366337Z","shell.execute_reply.started":"2025-03-17T12:55:44.684478Z","shell.execute_reply":"2025-03-17T12:55:49.365451Z"}},"outputs":[{"name":"stdout","text":"Collecting stanza\n  Downloading stanza-1.10.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.14.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.26.4)\nRequirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.32.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.4.2)\nRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from stanza) (2.2.1)\nRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.5.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.12.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->stanza) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->stanza) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->stanza) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->stanza) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->stanza) (2024.2.0)\nDownloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: stanza\nSuccessfully installed stanza-1.10.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import stanza\nimport os\n\n# Path to save Stanza models\nstanza_save_path = \"/kaggle/working/stanza_resources\"\nos.makedirs(stanza_save_path, exist_ok=True)\n\n# List of Stanza models for regional languages\nstanza_models = [\"en\", \"hi\", \"ta\", \"te\", \"mr\", \"ur\"]\n\n# Download and save Stanza models\nfor lang in stanza_models:\n    print(f\"⏳ Downloading Stanza model: {lang}\")\n    stanza.download(lang, model_dir=stanza_save_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:55:49.367487Z","iopub.execute_input":"2025-03-17T12:55:49.367836Z","iopub.status.idle":"2025-03-17T12:56:27.546840Z","shell.execute_reply.started":"2025-03-17T12:55:49.367806Z","shell.execute_reply":"2025-03-17T12:56:27.545963Z"}},"outputs":[{"name":"stdout","text":"⏳ Downloading Stanza model: en\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63aa8c29f27549dea098af9bb0dd4692"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/default.zip:   0%|          | …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a28a4dc5196d43719ac512e26ffbf2f2"}},"metadata":{}},{"name":"stdout","text":"⏳ Downloading Stanza model: hi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"874d0285c3a44833a09fc55843107510"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-hi/resolve/v1.10.0/models/default.zip:   0%|          | …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cb61a52847d42469b5ed16b23e882b8"}},"metadata":{}},{"name":"stdout","text":"⏳ Downloading Stanza model: ta\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7baa2dd34d804e8b9ef4f713c7cbf694"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-ta/resolve/v1.10.0/models/default.zip:   0%|          | …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d7ebf26d0954f57acc49159e10ba2a7"}},"metadata":{}},{"name":"stdout","text":"⏳ Downloading Stanza model: te\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbaa0401a98d406b9e7ea16f71f4a2c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-te/resolve/v1.10.0/models/default.zip:   0%|          | …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0085005b164847e1bc66994fee1ae746"}},"metadata":{}},{"name":"stdout","text":"⏳ Downloading Stanza model: mr\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba519998585747d6acb33689bbc65497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-mr/resolve/v1.10.0/models/default.zip:   0%|          | …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"616d1ade857848a097d28df7b48a6093"}},"metadata":{}},{"name":"stdout","text":"⏳ Downloading Stanza model: ur\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8764e2748dd24945898dcc2c3003cd4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-ur/resolve/v1.10.0/models/default.zip:   0%|          | …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af9a7e98d0041c784012f1caa85266b"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"!pip install langdetect\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:56:27.547793Z","iopub.execute_input":"2025-03-17T12:56:27.548505Z","iopub.status.idle":"2025-03-17T12:56:36.108625Z","shell.execute_reply.started":"2025-03-17T12:56:27.548465Z","shell.execute_reply":"2025-03-17T12:56:36.107727Z"}},"outputs":[{"name":"stdout","text":"Collecting langdetect\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.17.0)\nBuilding wheels for collected packages: langdetect\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=f06e93711cc3339c1955e4c143d52154b107bd3dcaf4714485c1efc08fffab50\n  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\nSuccessfully built langdetect\nInstalling collected packages: langdetect\nSuccessfully installed langdetect-1.0.9\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import spacy\nimport stanza\nimport langdetect\nimport subprocess\nimport os\n\n# 🔄 Install missing packages automatically\ntry:\n    import stanza\nexcept ModuleNotFoundError:\n    print(\"⏳ Installing Stanza...\")\n    subprocess.run([\"pip\", \"install\", \"stanza\"])\n\ntry:\n    import spacy\nexcept ModuleNotFoundError:\n    print(\"⏳ Installing spaCy...\")\n    subprocess.run([\"pip\", \"install\", \"spacy\"])\n\n# 📂 Define paths for saving models\nSPACY_PATH = \"/kaggle/working/spacy_models\"\nSTANZA_PATH = \"/kaggle/working/stanza_resources\"\nos.makedirs(SPACY_PATH, exist_ok=True)\nos.makedirs(STANZA_PATH, exist_ok=True)\n\n# 🌍 Load spaCy models for supported languages\nspacy_models = {\n    \"en\": \"en_core_web_sm\",\n    \"de\": \"de_core_news_sm\",\n    \"fr\": \"fr_core_news_sm\",\n    \"es\": \"es_core_news_sm\",\n    \"it\": \"it_core_news_sm\",\n    \"nl\": \"nl_core_news_sm\",\n    \"pt\": \"pt_core_news_sm\",\n    \"el\": \"el_core_news_sm\",\n    \"ru\": \"ru_core_news_sm\",\n    \"zh\": \"zh_core_web_sm\",\n    \"ja\": \"ja_core_news_sm\",\n    \"ko\": \"ko_core_news_sm\",\n}\n\n# 🛑 Load Stanza models for regional languages\nstanza_models = {\n    \"hi\": \"hi\",\n    \"ta\": \"ta\",\n    \"te\": \"te\",\n    \"mr\": \"mr\",\n    \"ur\": \"ur\",\n}\n\n# 🔹 Download and Load spaCy Models\nnlp_spacy = {}\nfor lang, model in spacy_models.items():\n    try:\n        nlp_spacy[lang] = spacy.load(f\"{SPACY_PATH}/{model}\")\n    except:\n        print(f\"⏳ Downloading spaCy model: {model}\")\n        subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", model])\n        nlp_spacy[lang] = spacy.load(model)\n        nlp_spacy[lang].to_disk(f\"{SPACY_PATH}/{model}\")\n\n# 🔹 Download and Load Stanza Models\nfor lang in stanza_models.values():\n    stanza.download(lang, model_dir=STANZA_PATH)\n\nnlp_stanza = {lang: stanza.Pipeline(lang, dir=STANZA_PATH) for lang in stanza_models.keys()}\n\n# 🔎 Language Detection Function\ndef detect_language(text):\n    \"\"\"Detects the language of the text using langdetect.\"\"\"\n    try:\n        return langdetect.detect(text)\n    except:\n        return \"en\"\n\n# ✨ Preprocessing Function\ndef preprocess_text(text):\n    \"\"\"Automatically preprocesses text based on detected language.\"\"\"\n    lang = detect_language(text)\n\n    if lang in nlp_spacy:\n        doc = nlp_spacy[lang](text)\n        clean_tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n    elif lang in nlp_stanza:\n        doc = nlp_stanza[lang](text)\n        clean_tokens = [word.lemma for sent in doc.sentences for word in sent.words if word.text.isalpha()]\n    else:\n        return text.lower()  # Default to lowercased text if no model is available\n\n    return \" \".join(clean_tokens).lower()\n\n# 📝 Example Usage\ntexts = [\n    \"NASA is launching a new mission to Mars!\",\n    \"नासा मंगल ग्रह के लिए एक नया मिशन शुरू कर रहा है।\",\n    \"நாசா செவ்வாய் கிரகத்திற்கு ஒரு புதிய திட்டத்தை அறிவித்துள்ளது!\",\n    \"El lanzamiento de la misión está programado para 2025.\",\n    \"La missione è programmata per il 2025.\",\n    \"Μια νέα αποστολή θα ξεκινήσει το 2025.\",\n]\n\nfor text in texts:\n    print(f\"Original: {text}\")\n    print(f\"Preprocessed: {preprocess_text(text)}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:56:36.110862Z","iopub.execute_input":"2025-03-17T12:56:36.111094Z","iopub.status.idle":"2025-03-17T12:57:38.686479Z","shell.execute_reply.started":"2025-03-17T12:56:36.111072Z","shell.execute_reply":"2025-03-17T12:57:38.685647Z"}},"outputs":[{"name":"stdout","text":"⏳ Downloading spaCy model: en_core_web_sm\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7ba015f5f1a40d08895e41a41f43e03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26b00af2b7cb4b0f91f92e07902b3dfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ba90cf4913c4c0cac53c5e2126b1eac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12122c719c624f66af1e915b0b113a92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc2c62fc5764e5fb27b3652d3159177"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b2838353bb946b084dc18b577eb48a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4f6338304744f8c805d3b9632cf57c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9570df5661243f9a91bf7e35a2cca87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36053aa7fc1a49319d4794d429f627d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aa76f2140d54010a3ec43c66585f3f6"}},"metadata":{}},{"name":"stdout","text":"Original: NASA is launching a new mission to Mars!\nPreprocessed: nasa launch new mission mars\n\nOriginal: नासा मंगल ग्रह के लिए एक नया मिशन शुरू कर रहा है।\nPreprocessed: एक करना\n\nOriginal: நாசா செவ்வாய் கிரகத்திற்கு ஒரு புதிய திட்டத்தை அறிவித்துள்ளது!\nPreprocessed: \n\nOriginal: El lanzamiento de la misión está programado para 2025.\nPreprocessed: lanzamiento misión programado\n\nOriginal: La missione è programmata per il 2025.\nPreprocessed: missione programmare\n\nOriginal: Μια νέα αποστολή θα ξεκινήσει το 2025.\nPreprocessed: νέος αποστολή ξεκινώ\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport spacy\nimport stanza\nimport torch\nfrom transformers import BartForConditionalGeneration, BartTokenizer\nfrom concurrent.futures import ThreadPoolExecutor\nimport re\nimport subprocess\nimport os\n\n# 🔄 Install missing libraries (if needed)\ntry:\n    import stanza\nexcept ModuleNotFoundError:\n    subprocess.run([\"pip\", \"install\", \"stanza\"])\n\ntry:\n    import spacy\nexcept ModuleNotFoundError:\n    subprocess.run([\"pip\", \"install\", \"spacy\"])\n\n# 📂 Paths for saving models in Kaggle\nSPACY_PATH = \"/kaggle/working/spacy_models\"\nSTANZA_PATH = \"/kaggle/working/stanza_resources\"\nos.makedirs(SPACY_PATH, exist_ok=True)\nos.makedirs(STANZA_PATH, exist_ok=True)\n\n# 🌍 Load language models\ntry:\n    nlp_spacy = spacy.load(f\"{SPACY_PATH}/en_core_web_sm\")\nexcept:\n    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n    nlp_spacy = spacy.load(\"en_core_web_sm\")\n    nlp_spacy.to_disk(f\"{SPACY_PATH}/en_core_web_sm\")\n\nstanza.download(\"en\", model_dir=STANZA_PATH)\nnlp_stanza = stanza.Pipeline(lang='en', processors='tokenize,lemma', batch_size=64, use_gpu=True, dir=STANZA_PATH)\n\n# 🔹 Load BART model and tokenizer from Hugging Face (no local path required in Kaggle)\ntry:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n    model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n    print(\"✅ BART model loaded successfully!\")\nexcept Exception as e:\n    print(f\"❌ Error loading BART model: {e}\")\n    exit()\n\n# 🧹 Text cleaning function\ndef clean_text(text):\n    text = str(text).lower().strip()\n    text = re.sub(r'http\\S+|www.\\S+', '', text)  # Remove URLs\n    text = re.sub(r'\\s+', ' ', text)             # Remove extra spaces\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)   # Remove special characters\n    return text\n\n# 🔄 Tokenization and lemmatization using SpaCy\ndef preprocess_spacy(text):\n    try:\n        doc = nlp_spacy(text)\n        return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n    except Exception:\n        return text  # Fallback if processing fails\n\n# 🔄 Tokenization and lemmatization using Stanza\ndef preprocess_stanza(text):\n    try:\n        doc = nlp_stanza(text)\n        return \" \".join([word.lemma for sentence in doc.sentences for word in sentence.words])\n    except Exception:\n        return text  # Fallback if processing fails\n\n# 🔹 Batch Abstractive summarization using BART\ndef abstractive_summarization_batch(texts, max_len=130):\n    try:\n        inputs = tokenizer(texts, return_tensors=\"pt\", max_length=1024, truncation=True, padding=True).to(device)\n        summary_ids = model.generate(inputs[\"input_ids\"], max_length=max_len, num_beams=4, early_stopping=True)\n        return [tokenizer.decode(s, skip_special_tokens=True) for s in summary_ids]\n    except Exception:\n        return texts  # Fallback if summarization fails\n\n# 🔄 Batch processing with parallel execution\ndef process_chunk(chunk):\n    chunk.columns = chunk.columns.str.strip()\n\n    # 🔎 Updated text column identification\n    if 'Text' not in chunk.columns:\n        print(f\"❌ No suitable text column found in chunk. Skipping...\")\n        return pd.DataFrame()\n\n    print(f\"✅ Processing chunk with column 'Text'\")\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        chunk['cleaned_text'] = list(executor.map(clean_text, chunk['Text']))\n        chunk['spacy_text'] = list(executor.map(preprocess_spacy, chunk['cleaned_text']))\n        chunk['stanza_text'] = list(executor.map(preprocess_stanza, chunk['cleaned_text']))\n        chunk['summary'] = abstractive_summarization_batch(chunk['cleaned_text'].tolist())\n\n    return chunk\n\n# 🔹 Load and process dataset in chunks\nchunk_size = 1000\noutput_path = '/kaggle/working/preprocessed_train.csv'\n\ntry:\n    for idx, chunk in enumerate(pd.read_csv('/kaggle/input/summary/BBCarticles.csv', encoding='windows-1252', chunksize=chunk_size)):\n        processed_chunk = process_chunk(chunk)\n\n        if not processed_chunk.empty:\n            processed_chunk.to_csv(output_path, mode='a', index=False, header=not idx, float_format='%.3f')\n            print(f\"✅ Chunk {idx + 1} saved successfully.\")\n\n    print(f\"✅ Preprocessing completed successfully! Data saved to: {output_path}\")\n\nexcept FileNotFoundError:\n    print(\"❌ Error: 'BBCarticles.csv' not found.\")\nexcept Exception as e:\n    print(f\"❌ Unexpected Error: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:57:38.687524Z","iopub.execute_input":"2025-03-17T12:57:38.687879Z","iopub.status.idle":"2025-03-17T13:05:03.577863Z","shell.execute_reply.started":"2025-03-17T12:57:38.687853Z","shell.execute_reply":"2025-03-17T13:05:03.577005Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d4d892616ba41c4aabbdb6fb1ed4805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"452a74e1bd524353935e772473b3271b"}},"metadata":{}},{"name":"stdout","text":"✅ BART model loaded successfully!\n✅ Processing chunk with column 'Text'\n✅ Chunk 1 saved successfully.\n✅ Processing chunk with column 'Text'\n✅ Chunk 2 saved successfully.\n✅ Processing chunk with column 'Text'\n✅ Chunk 3 saved successfully.\n✅ Preprocessing completed successfully! Data saved to: /kaggle/working/preprocessed_train.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:05:03.578800Z","iopub.execute_input":"2025-03-17T13:05:03.579121Z","iopub.status.idle":"2025-03-17T13:05:07.271922Z","shell.execute_reply.started":"2025-03-17T13:05:03.579088Z","shell.execute_reply":"2025-03-17T13:05:07.270855Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport torch\nimport spacy\nimport stanza\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nfrom transformers import BartForConditionalGeneration, BartTokenizer\nfrom concurrent.futures import ThreadPoolExecutor\nfrom datasets import load_dataset\nimport csv\nimport glob  # For detecting completed chunks\n\n# ✅ Load Language Models\nnlp_spacy = spacy.load(\"en_core_web_sm\")\nnlp_stanza = stanza.Pipeline(lang='en', processors='tokenize,lemma', batch_size=32, use_gpu=True)\n\n# ✅ Preprocessing Functions\ndef clean_text(text):\n    return \" \".join([token.lemma_ for token in nlp_spacy(text) if not token.is_stop and not token.is_punct])\n\ndef preprocess_stanza(text):\n    doc = nlp_stanza(text)\n    return \" \".join([word.lemma for sentence in doc.sentences for word in sentence.words])\n\ndef preprocess_data(examples):\n    cleaned_texts = preprocess_in_parallel(examples['text'], clean_text)\n    model_inputs = tokenizer(\n        cleaned_texts, \n        max_length=256,   \n        truncation=True, \n        padding='max_length'\n    )\n    labels = tokenizer(\n        examples['summary'],\n        max_length=130,\n        truncation=True,\n        padding='max_length'\n    ).input_ids\n\n    model_inputs['labels'] = [\n        [-100 if token == tokenizer.pad_token_id else token for token in label]\n        for label in labels\n    ]\n    return model_inputs\n\n# ✅ Parallel Processing for Faster Text Cleaning\ndef preprocess_in_parallel(text_list, function, max_workers=8):\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        return list(executor.map(function, text_list))\n\n# ✅ Save Preprocessed Data as CSV\ndef save_dataset_as_csv(dataset, lang_code, chunk_number):\n    output_path = f\"/kaggle/working/{lang_code}_chunk_{chunk_number}.csv\"\n    dataset.to_pandas().to_csv(output_path, index=False)\n    print(f\"✅ Saved: {output_path}\")\n\n# ✅ Track Completed Chunks\ndef get_completed_chunks(lang_code):\n    existing_files = glob.glob(f\"/kaggle/working/{lang_code}_chunk_*.csv\")\n    completed_chunks = [int(file.split('_')[-1].split('.')[0]) for file in existing_files]\n    return max(completed_chunks) + 1 if completed_chunks else 0\n\n# ✅ Chunk-Based Processing with Resume Functionality\ndef process_and_save_in_chunks(dataset, chunk_size=2000, lang_code=\"english\"):\n    total_samples = len(dataset['train'])\n    start_chunk = get_completed_chunks(lang_code)\n\n    for start_idx in range(start_chunk * chunk_size, total_samples, chunk_size):\n        end_idx = min(start_idx + chunk_size, total_samples)\n        dataset_chunk = dataset['train'].select(range(start_idx, end_idx))\n\n        processed_chunk = dataset_chunk.map(preprocess_data, batched=True)\n        save_dataset_as_csv(processed_chunk, lang_code, chunk_number=start_idx // chunk_size)\n\n        print(f\"✅ Processed and saved chunk {start_idx // chunk_size + 1} for {lang_code}\")\n\n# ✅ Main Code Execution\ntokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n\nlanguages = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"spanish\", \"french\", \"german\", \"chinese\", \"japanese\"]\n\n# ✅ Load XLSum for Other Languages\nfor lang in languages:\n    try:\n        dataset = load_dataset(\"csebuetnlp/xlsum\", lang)\n        process_and_save_in_chunks(dataset, lang_code=lang)\n        print(f\"✅ Successfully processed data for: {lang}\")\n    except Exception as e:\n        print(f\"❌ Failed to load data for {lang}: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:05:07.273061Z","iopub.execute_input":"2025-03-17T13:05:07.273302Z","iopub.status.idle":"2025-03-17T17:29:09.855825Z","shell.execute_reply.started":"2025-03-17T13:05:07.273279Z","shell.execute_reply":"2025-03-17T17:29:09.854908Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49cf20e678f44b69976f5f9e87410cf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/tokenize/combined.pt:   0%|   …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dc24bcd10824fc7a657a3b648fe8ebe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/mwt/combined.pt:   0%|        …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dded7a3e60234e99b53c11dbeb54a4bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/lemma/combined_nocharlm.pt:   …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63845b4b7aa44a23a7f4b6c78ec4b385"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/14.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac28cf5436e147cba5f5085da9462b8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"xlsum.py:   0%|          | 0.00/4.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb363043d5c54665ae6977fce30fdda7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/187M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ecda8a33772474bbbc332824d562c11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0001.parquet:   0%|          | 0.00/19.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8e07d7ca53746cdb0c973645d3a94a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/21.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5443fbb6b57c4418899ed1a2a8efa01a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/21.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eca1e17114664bf1a6e4683638322671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/70778 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9e27f879e9f43398af0f0b4c8e67bd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/8847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29b99540fbc04d14a8dbd2efb11bb2f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/8847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f7a0763104547b3bdc69f0979b78ced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a94cede87444c09b681812993404d79"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_0.csv\n✅ Processed and saved chunk 1 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecce9b5d785a46e2900a238363cb490f"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_1.csv\n✅ Processed and saved chunk 2 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"987e961a7dcd4c0d84b3f80ebf1d99cc"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_2.csv\n✅ Processed and saved chunk 3 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de20ed956da14ca2b3092553398abf1c"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_3.csv\n✅ Processed and saved chunk 4 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455a9052e22c4783b7fdbd316bade2a4"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_4.csv\n✅ Processed and saved chunk 5 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d53f017ab854df5a1a514fec7016203"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_5.csv\n✅ Processed and saved chunk 6 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e42401d242ce4bc3aef055161df03303"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_6.csv\n✅ Processed and saved chunk 7 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2f78ba0961843999c8a72f9c36cdcb3"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_7.csv\n✅ Processed and saved chunk 8 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16a016aa27e04571a7e92137e6477134"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_8.csv\n✅ Processed and saved chunk 9 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10cfdc1f93c43a29583384ff9750a7c"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_9.csv\n✅ Processed and saved chunk 10 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb5a5160bf7d426fa832d67731976ccc"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_10.csv\n✅ Processed and saved chunk 11 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df2faf89fd894c19abf69ec7fbe16b1d"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_11.csv\n✅ Processed and saved chunk 12 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e97bff0d154d40e38dd2e33786f271cc"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_12.csv\n✅ Processed and saved chunk 13 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a2033431cc548069c12e31ead4ce85a"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_13.csv\n✅ Processed and saved chunk 14 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a43838e4cf446eb2ab09e154a40a8c"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_14.csv\n✅ Processed and saved chunk 15 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6417ccc84f2744a29e982f71cdf508ff"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_15.csv\n✅ Processed and saved chunk 16 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25fe53f3fb7941a6b94acf19dc6f78cf"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_16.csv\n✅ Processed and saved chunk 17 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11c14aea4be645eb8484e639d803e1da"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_17.csv\n✅ Processed and saved chunk 18 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27896d0ab2284254a0fb0939d040d228"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_18.csv\n✅ Processed and saved chunk 19 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"722449db5def450c9c4919648d1a7eb4"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_19.csv\n✅ Processed and saved chunk 20 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72dbd7298e6c4ceba0c1d83d974b30f2"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_20.csv\n✅ Processed and saved chunk 21 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4cf7a697bf148349da3ec0515cb64df"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_21.csv\n✅ Processed and saved chunk 22 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c84de9e94a504904bf114d337cc9a6a5"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_22.csv\n✅ Processed and saved chunk 23 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e704fafbdcc44629a514f425dad96cd"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_23.csv\n✅ Processed and saved chunk 24 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"428f6289c614478498756abc2bbed8d0"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_24.csv\n✅ Processed and saved chunk 25 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df5061a03aff4eb28c8c628a8571a231"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_25.csv\n✅ Processed and saved chunk 26 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83728962fd634737996aed0384432e1e"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_26.csv\n✅ Processed and saved chunk 27 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25d2f82030c04db0882af254c4210e19"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_27.csv\n✅ Processed and saved chunk 28 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"593e52f409d74f1588919575d366e4c7"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_28.csv\n✅ Processed and saved chunk 29 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6e97ed4c7249cd9bb79eb0a62cd83d"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_29.csv\n✅ Processed and saved chunk 30 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f282825487b040a2b326a487a3ccaf8a"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_30.csv\n✅ Processed and saved chunk 31 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a265807893074daa801c3ccaea50e880"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_31.csv\n✅ Processed and saved chunk 32 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d3728b1af474c789814651ce41ef1aa"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_32.csv\n✅ Processed and saved chunk 33 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b271fd403454de38ddcc186271b142a"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_33.csv\n✅ Processed and saved chunk 34 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"370f39417ec84cbcbc0c1e68d7ade23d"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_34.csv\n✅ Processed and saved chunk 35 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/778 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92bf1f06ea024fbdb61d12e157681e30"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/hindi_chunk_35.csv\n✅ Processed and saved chunk 36 for hindi\n✅ Successfully processed data for: hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/61.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134062ce5b564ed8be09719c62ca8a8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/6.97M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9970c692bd614d27a353e54f5e8682ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/7.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4063d0aac12144429f7c4d12d07fa178"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16222 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f02b9b2c75c4db2b3285bc9bc8a5152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2027 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41633ef047b24f788dfe084d228d512e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2027 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e7f6a212ef4dd2a4730c6737486463"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b084cc22f8ff4f0daf80068187e7787f"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/tamil_chunk_0.csv\n✅ Processed and saved chunk 1 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b9d06027c874a6e946842792a9addff"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/tamil_chunk_1.csv\n✅ Processed and saved chunk 2 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d4be8f11c7e4af08229b40110fc2242"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/tamil_chunk_2.csv\n✅ Processed and saved chunk 3 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87186f20f191454b9dccdb21eebe61f9"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/tamil_chunk_3.csv\n✅ Processed and saved chunk 4 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a07d4edd1be4134b070ede7104d1f40"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/tamil_chunk_4.csv\n✅ Processed and saved chunk 5 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6ba6748ffa2487abcf1ef3960862b80"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/tamil_chunk_5.csv\n✅ Processed and saved chunk 6 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"460c05a4185542dca8160291cb6355d2"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/tamil_chunk_6.csv\n✅ Processed and saved chunk 7 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a735e57ff0f1498fa67341da277161b6"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/tamil_chunk_7.csv\n✅ Processed and saved chunk 8 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/222 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c17a1150934491f9b59363872160bc8"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/tamil_chunk_8.csv\n✅ Processed and saved chunk 9 for tamil\n✅ Successfully processed data for: tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/46.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db36e2b5b1d643abb06e5f5178e1a4f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/5.01M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5430ab529a2842a0b964a89d8cbc95b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/4.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fee0aa2fcf8f4b70af4caee0cf85f031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10421 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f959728a425547d1910ff59c3840c07c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1302 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4539fb617624f6e8974536fe721148b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1302 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04c4bd7962b14967956d00519eba5a64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2d7474f133745a9a6d70ba46d0f34f7"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/telugu_chunk_0.csv\n✅ Processed and saved chunk 1 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8f185151b2d45e18aac349a34d56ad1"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/telugu_chunk_1.csv\n✅ Processed and saved chunk 2 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8c320e712b547ff8ae4194be5fda8e3"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/telugu_chunk_2.csv\n✅ Processed and saved chunk 3 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b44e6477037417682845b14fe931725"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/telugu_chunk_3.csv\n✅ Processed and saved chunk 4 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e5641712d084152a4aa2b26e0a77820"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/telugu_chunk_4.csv\n✅ Processed and saved chunk 5 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/421 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e93d6dc1ad8c48c6a5dbd53e925937a2"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/telugu_chunk_5.csv\n✅ Processed and saved chunk 6 for telugu\n✅ Successfully processed data for: telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/50.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f56f35fe906f49ea9f768375f7f13d3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/5.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ebb973fb51434e93f28ab51215b150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f8bf0425a4944aaaf5bf57fe6ae174a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10903 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ee9312e5284c939b3d1c3362313427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8221ee1ca649479e9b737ecad90847"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38e9c423e3e04d88967467fc66589404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b3311058aa942c98329df372b55cd50"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/marathi_chunk_0.csv\n✅ Processed and saved chunk 1 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0238cf75af2946a4930043bba3287d1c"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/marathi_chunk_1.csv\n✅ Processed and saved chunk 2 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9773d41f9c4140e48b5479a78fa38006"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/marathi_chunk_2.csv\n✅ Processed and saved chunk 3 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"088c6eb545484608ab1e6e172de573b4"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/marathi_chunk_3.csv\n✅ Processed and saved chunk 4 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2ab31aaa2ac44c28a383bd32166396b"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/marathi_chunk_4.csv\n✅ Processed and saved chunk 5 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/903 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"841297df36ac44208a04e37203b43669"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/marathi_chunk_5.csv\n✅ Processed and saved chunk 6 for marathi\n✅ Successfully processed data for: marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/125M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1063be3a8b7645a2b927ca906a62d97e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e35d669f71f74f84b06bbfdb287cdff9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f5bde6deeb45ffb580dd1e98f898fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/38110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cee9dbaf7d5d44a086ea7b8214368f51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4763 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17427381367f471e9d23d1cbdb7e1379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/4763 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41b0982b61c440b195afb70c426516e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf52a770b5424ff1872e6243a932d92b"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_0.csv\n✅ Processed and saved chunk 1 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2218f6619f6a4c72a091d912cbe57df3"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_1.csv\n✅ Processed and saved chunk 2 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8432e5bb58441f5958365cfbd3b8bfe"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_2.csv\n✅ Processed and saved chunk 3 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fef643ce68914ae3acd6beef76118461"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_3.csv\n✅ Processed and saved chunk 4 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0caf3e5bb2f4491080a220737dca69c5"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_4.csv\n✅ Processed and saved chunk 5 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11cdffa706a84e77ab6c72a496ad6a24"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_5.csv\n✅ Processed and saved chunk 6 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01f51065f5474fde9b8ce4a6a5f2fcd1"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_6.csv\n✅ Processed and saved chunk 7 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9fd26fa506744ecab4f2700657dae28"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_7.csv\n✅ Processed and saved chunk 8 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"662a109a5bb4441a84f45a11df62adbe"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_8.csv\n✅ Processed and saved chunk 9 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4772ad375d7942d3bccbc81a447d2025"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_9.csv\n✅ Processed and saved chunk 10 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfef7cd0ff3e42559385980880a0dc68"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_10.csv\n✅ Processed and saved chunk 11 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba0e26732e51472195f8c0802f41dfe3"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_11.csv\n✅ Processed and saved chunk 12 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f591d26a35c84b00817d429ce2d9b092"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_12.csv\n✅ Processed and saved chunk 13 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b239a96b3e944b2291c64a113b15d9f6"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_13.csv\n✅ Processed and saved chunk 14 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6bbf0ca4b3844f6991f633a8628930d"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_14.csv\n✅ Processed and saved chunk 15 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d34769ba9970448eb17c8493b430a2fb"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_15.csv\n✅ Processed and saved chunk 16 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb5d0b4aa98c4078a4daa17ec8365df2"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_16.csv\n✅ Processed and saved chunk 17 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae3e573880d3469fb80e587965c17adf"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_17.csv\n✅ Processed and saved chunk 18 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e009f7d058324b62a624c68ca43d2cd6"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_18.csv\n✅ Processed and saved chunk 19 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"860bac847a5a4ba0b25478e2d2b4893a"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/spanish_chunk_19.csv\n✅ Processed and saved chunk 20 for spanish\n✅ Successfully processed data for: spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf2caa420a642ebac7ed23cd10bdd1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/1.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f768df709038461a8690aeefb91dea33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/1.74M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e94b7967d7c44d6be4fc5a0cd159611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/8697 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17ce7be5afb64fab98fa7ed04a592ba1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1086 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25973f112dc9401580f71ae842a03be0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1086 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b11a19f3b967441680b643fb02df327e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aa5cc209bbd4ffe9ef02ed3d5012d6c"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/french_chunk_0.csv\n✅ Processed and saved chunk 1 for french\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b9c8e6c7a5f4373a7096ce5412f861c"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/french_chunk_1.csv\n✅ Processed and saved chunk 2 for french\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a94fd0a7e024955b3699cab22dbc275"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/french_chunk_2.csv\n✅ Processed and saved chunk 3 for french\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bced9f8550e475690b5e0b3d6d8876e"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/french_chunk_3.csv\n✅ Processed and saved chunk 4 for french\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/697 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16ce90df4d304f67b7b3ed483657e37d"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/french_chunk_4.csv\n✅ Processed and saved chunk 5 for french\n✅ Successfully processed data for: french\n❌ Failed to load data for german: BuilderConfig 'german' not found. Available: ['amharic', 'arabic', 'azerbaijani', 'bengali', 'burmese', 'chinese_simplified', 'chinese_traditional', 'english', 'french', 'gujarati', 'hausa', 'hindi', 'igbo', 'indonesian', 'japanese', 'kirundi', 'korean', 'kyrgyz', 'marathi', 'nepali', 'oromo', 'pashto', 'persian', 'pidgin', 'portuguese', 'punjabi', 'russian', 'scottish_gaelic', 'serbian_cyrillic', 'serbian_latin', 'sinhala', 'somali', 'spanish', 'swahili', 'tamil', 'telugu', 'thai', 'tigrinya', 'turkish', 'ukrainian', 'urdu', 'uzbek', 'vietnamese', 'welsh', 'yoruba']\n❌ Failed to load data for chinese: BuilderConfig 'chinese' not found. Available: ['amharic', 'arabic', 'azerbaijani', 'bengali', 'burmese', 'chinese_simplified', 'chinese_traditional', 'english', 'french', 'gujarati', 'hausa', 'hindi', 'igbo', 'indonesian', 'japanese', 'kirundi', 'korean', 'kyrgyz', 'marathi', 'nepali', 'oromo', 'pashto', 'persian', 'pidgin', 'portuguese', 'punjabi', 'russian', 'scottish_gaelic', 'serbian_cyrillic', 'serbian_latin', 'sinhala', 'somali', 'spanish', 'swahili', 'tamil', 'telugu', 'thai', 'tigrinya', 'turkish', 'ukrainian', 'urdu', 'uzbek', 'vietnamese', 'welsh', 'yoruba']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/21.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68f87ce3ddae46c0a5d118d1fd5f06ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/2.54M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86dcded8ab684f2fb6b716b6d7e83fd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f67f52b839c43ac96e733ed87aea163"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a55737972eb5477f98614adaa9ef2e7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/889 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"def8beb0dd744e28ba84a7d1fb94e6eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/889 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af440db40a0f4e938e2e1b04ed22473a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4b44da2f4af4040a7b3a84141496c74"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/japanese_chunk_0.csv\n✅ Processed and saved chunk 1 for japanese\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8584d6990a4b82852cf1c6254e5779"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/japanese_chunk_1.csv\n✅ Processed and saved chunk 2 for japanese\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b562f0af13894c22aa1ebc526e7bf9b0"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/japanese_chunk_2.csv\n✅ Processed and saved chunk 3 for japanese\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dce107653084e2dac05aa097be085bb"}},"metadata":{}},{"name":"stdout","text":"✅ Saved: /kaggle/working/japanese_chunk_3.csv\n✅ Processed and saved chunk 4 for japanese\n✅ Successfully processed data for: japanese\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BartForConditionalGeneration, BartTokenizer\nfrom transformers import AdamW, get_scheduler\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\n\n# ✅ Custom Dataset Class\nclass SummarizationDataset(Dataset):\n    def __init__(self, file_path, tokenizer, max_input_len=256, max_output_len=130):\n        self.data = pd.read_csv(file_path).dropna()\n        self.tokenizer = tokenizer\n        self.max_input_len = max_input_len\n        self.max_output_len = max_output_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = str(self.data.iloc[idx]['text']).strip()\n        summary = str(self.data.iloc[idx]['summary']).strip()\n\n        inputs = self.tokenizer(text, max_length=self.max_input_len, padding='max_length', truncation=True, return_tensors='pt')\n        labels = self.tokenizer(summary, max_length=self.max_output_len, padding='max_length', truncation=True, return_tensors='pt').input_ids\n\n        labels[labels == self.tokenizer.pad_token_id] = -100\n\n        return {\n            'input_ids': inputs['input_ids'].squeeze(0),\n            'attention_mask': inputs['attention_mask'].squeeze(0),\n            'labels': labels.squeeze(0)\n        }\n\n# ✅ DataLoader Function\ndef get_data_loaders(batch_size=8):\n    train_loaders, val_loaders = [], []\n    languages = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"spanish\", \"french\", \"japanese\"]\n\n    for lang in languages:\n        train_file = f\"/kaggle/working/{lang}_chunk_0.csv\"\n        val_file = f\"/kaggle/working/{lang}_chunk_1.csv\"\n\n        train_dataset = SummarizationDataset(train_file, tokenizer)\n        val_dataset = SummarizationDataset(val_file, tokenizer)\n\n        train_loaders.append(DataLoader(train_dataset, batch_size=batch_size, shuffle=True))\n        val_loaders.append(DataLoader(val_dataset, batch_size=batch_size))\n\n    return train_loaders, val_loaders\n\n# ✅ Training Loop\ndef train_model(model, train_loaders, val_loaders, epochs=3, lr=3e-5):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n\n    optimizer = AdamW(model.parameters(), lr=lr)\n    lr_scheduler = get_scheduler(\n        name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=epochs * len(train_loaders[0])\n    )\n\n    loss_fn = nn.CrossEntropyLoss()\n\n    best_val_loss = float('inf')\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss, correct_train, total_train = 0, 0, 0\n\n        for train_loader in train_loaders:\n            for batch in tqdm(train_loader, desc=f\"🚂 Training Epoch {epoch + 1}\"):\n                optimizer.zero_grad()\n\n                inputs = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n\n                outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)\n                loss = outputs.loss\n                loss.backward()\n                optimizer.step()\n                lr_scheduler.step()\n\n                total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loaders[0])\n        print(f\"✅ Epoch {epoch + 1}/{epochs}, Avg Training Loss: {avg_loss:.4f}\")\n\n        # Validation Step\n        model.eval()\n        val_loss = 0\n\n        with torch.no_grad():\n            for val_loader in val_loaders:\n                for batch in tqdm(val_loader, desc=\"🔎 Validating\"):\n                    inputs = batch['input_ids'].to(device)\n                    attention_mask = batch['attention_mask'].to(device)\n                    labels = batch['labels'].to(device)\n\n                    outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)\n                    val_loss += outputs.loss.item()\n\n        avg_val_loss = val_loss / len(val_loaders[0])\n        print(f\"🔹 Validation Loss: {avg_val_loss:.4f}\")\n\n        # Save Best Model\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            model.save_pretrained(\"./best_model\")\n            print(\"💾 Model saved as 'best_model'\")\n\n# ✅ Load Model and Tokenizer\ntokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\nmodel = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n\n# ✅ Load Data and Train\ntrain_loaders, val_loaders = get_data_loaders(batch_size=8)\ntrain_model(model, train_loaders, val_loaders, epochs=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T20:24:44.248620Z","iopub.status.idle":"2025-03-17T20:24:44.248918Z","shell.execute_reply":"2025-03-17T20:24:44.248803Z"}},"outputs":[],"execution_count":null}]}