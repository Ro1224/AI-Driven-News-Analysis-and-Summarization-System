{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11050513,"sourceType":"datasetVersion","datasetId":6884312}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\n\n# Load tokenizer and model directly from Hugging Face Hub\nmodel_name = \"facebook/bart-large-cnn\"\n\n# Load tokenizer and model\nbart_tokenizer = BartTokenizer.from_pretrained(model_name)\nbart_model = BartForConditionalGeneration.from_pretrained(model_name)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:53:11.385693Z","iopub.execute_input":"2025-03-17T12:53:11.385987Z","iopub.status.idle":"2025-03-17T12:53:42.443008Z","shell.execute_reply.started":"2025-03-17T12:53:11.385957Z","shell.execute_reply":"2025-03-17T12:53:42.442024Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"931c3c4b6d85492e835563c3b5c18802"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9c59f046b3847caaf061ea204b00517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc8bf8185d2464aab74c5ff676e4733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5e79c054434e29b219b42ff054d870"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f890c96d72c54ef1bc8dff7c495c3b1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63b4c5164572441ba3416de5fbf66b65"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import spacy\nimport subprocess\nimport os\n\n# Path to save spaCy models\nspacy_save_path = \"/kaggle/working/spacy_models\"\nos.makedirs(spacy_save_path, exist_ok=True)\n\n# List of spaCy models for supported languages\nspacy_models = [\n    \"en_core_web_sm\", \"de_core_news_sm\", \"fr_core_news_sm\", \"es_core_news_sm\",\n    \"it_core_news_sm\", \"nl_core_news_sm\", \"pt_core_news_sm\", \"el_core_news_sm\",\n    \"ru_core_news_sm\", \"zh_core_web_sm\", \"ja_core_news_sm\", \"ko_core_news_sm\"\n]\n\n# Download and save spaCy models\nfor model in spacy_models:\n    try:\n        spacy.load(model)\n    except:\n        print(f\"‚è≥ Downloading spaCy model: {model}\")\n        subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", model])\n        spacy.load(model).to_disk(f\"{spacy_save_path}/{model}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:53:42.443907Z","iopub.execute_input":"2025-03-17T12:53:42.444539Z","iopub.status.idle":"2025-03-17T12:55:44.682992Z","shell.execute_reply.started":"2025-03-17T12:53:42.444512Z","shell.execute_reply":"2025-03-17T12:55:44.682046Z"}},"outputs":[{"name":"stdout","text":"‚è≥ Downloading spaCy model: de_core_news_sm\n‚è≥ Downloading spaCy model: fr_core_news_sm\n‚è≥ Downloading spaCy model: es_core_news_sm\n‚è≥ Downloading spaCy model: it_core_news_sm\n‚è≥ Downloading spaCy model: nl_core_news_sm\n‚è≥ Downloading spaCy model: pt_core_news_sm\n‚è≥ Downloading spaCy model: el_core_news_sm\n‚è≥ Downloading spaCy model: ru_core_news_sm\n‚è≥ Downloading spaCy model: zh_core_web_sm\n‚è≥ Downloading spaCy model: ja_core_news_sm\n‚è≥ Downloading spaCy model: ko_core_news_sm\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install stanza\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:55:44.683924Z","iopub.execute_input":"2025-03-17T12:55:44.684515Z","iopub.status.idle":"2025-03-17T12:55:49.366337Z","shell.execute_reply.started":"2025-03-17T12:55:44.684478Z","shell.execute_reply":"2025-03-17T12:55:49.365451Z"}},"outputs":[{"name":"stdout","text":"Collecting stanza\n  Downloading stanza-1.10.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.14.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.26.4)\nRequirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.32.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.4.2)\nRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from stanza) (2.2.1)\nRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.5.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.12.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->stanza) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->stanza) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->stanza) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->stanza) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->stanza) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->stanza) (2024.2.0)\nDownloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: stanza\nSuccessfully installed stanza-1.10.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import stanza\nimport os\n\n# Path to save Stanza models\nstanza_save_path = \"/kaggle/working/stanza_resources\"\nos.makedirs(stanza_save_path, exist_ok=True)\n\n# List of Stanza models for regional languages\nstanza_models = [\"en\", \"hi\", \"ta\", \"te\", \"mr\", \"ur\"]\n\n# Download and save Stanza models\nfor lang in stanza_models:\n    print(f\"‚è≥ Downloading Stanza model: {lang}\")\n    stanza.download(lang, model_dir=stanza_save_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:55:49.367487Z","iopub.execute_input":"2025-03-17T12:55:49.367836Z","iopub.status.idle":"2025-03-17T12:56:27.546840Z","shell.execute_reply.started":"2025-03-17T12:55:49.367806Z","shell.execute_reply":"2025-03-17T12:56:27.545963Z"}},"outputs":[{"name":"stdout","text":"‚è≥ Downloading Stanza model: en\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63aa8c29f27549dea098af9bb0dd4692"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/default.zip:   0%|          | ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a28a4dc5196d43719ac512e26ffbf2f2"}},"metadata":{}},{"name":"stdout","text":"‚è≥ Downloading Stanza model: hi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"874d0285c3a44833a09fc55843107510"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-hi/resolve/v1.10.0/models/default.zip:   0%|          | ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cb61a52847d42469b5ed16b23e882b8"}},"metadata":{}},{"name":"stdout","text":"‚è≥ Downloading Stanza model: ta\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7baa2dd34d804e8b9ef4f713c7cbf694"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-ta/resolve/v1.10.0/models/default.zip:   0%|          | ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d7ebf26d0954f57acc49159e10ba2a7"}},"metadata":{}},{"name":"stdout","text":"‚è≥ Downloading Stanza model: te\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbaa0401a98d406b9e7ea16f71f4a2c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-te/resolve/v1.10.0/models/default.zip:   0%|          | ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0085005b164847e1bc66994fee1ae746"}},"metadata":{}},{"name":"stdout","text":"‚è≥ Downloading Stanza model: mr\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba519998585747d6acb33689bbc65497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-mr/resolve/v1.10.0/models/default.zip:   0%|          | ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"616d1ade857848a097d28df7b48a6093"}},"metadata":{}},{"name":"stdout","text":"‚è≥ Downloading Stanza model: ur\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8764e2748dd24945898dcc2c3003cd4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-ur/resolve/v1.10.0/models/default.zip:   0%|          | ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af9a7e98d0041c784012f1caa85266b"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"!pip install langdetect\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:56:27.547793Z","iopub.execute_input":"2025-03-17T12:56:27.548505Z","iopub.status.idle":"2025-03-17T12:56:36.108625Z","shell.execute_reply.started":"2025-03-17T12:56:27.548465Z","shell.execute_reply":"2025-03-17T12:56:36.107727Z"}},"outputs":[{"name":"stdout","text":"Collecting langdetect\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.17.0)\nBuilding wheels for collected packages: langdetect\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=f06e93711cc3339c1955e4c143d52154b107bd3dcaf4714485c1efc08fffab50\n  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\nSuccessfully built langdetect\nInstalling collected packages: langdetect\nSuccessfully installed langdetect-1.0.9\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import spacy\nimport stanza\nimport langdetect\nimport subprocess\nimport os\n\n# üîÑ Install missing packages automatically\ntry:\n    import stanza\nexcept ModuleNotFoundError:\n    print(\"‚è≥ Installing Stanza...\")\n    subprocess.run([\"pip\", \"install\", \"stanza\"])\n\ntry:\n    import spacy\nexcept ModuleNotFoundError:\n    print(\"‚è≥ Installing spaCy...\")\n    subprocess.run([\"pip\", \"install\", \"spacy\"])\n\n# üìÇ Define paths for saving models\nSPACY_PATH = \"/kaggle/working/spacy_models\"\nSTANZA_PATH = \"/kaggle/working/stanza_resources\"\nos.makedirs(SPACY_PATH, exist_ok=True)\nos.makedirs(STANZA_PATH, exist_ok=True)\n\n# üåç Load spaCy models for supported languages\nspacy_models = {\n    \"en\": \"en_core_web_sm\",\n    \"de\": \"de_core_news_sm\",\n    \"fr\": \"fr_core_news_sm\",\n    \"es\": \"es_core_news_sm\",\n    \"it\": \"it_core_news_sm\",\n    \"nl\": \"nl_core_news_sm\",\n    \"pt\": \"pt_core_news_sm\",\n    \"el\": \"el_core_news_sm\",\n    \"ru\": \"ru_core_news_sm\",\n    \"zh\": \"zh_core_web_sm\",\n    \"ja\": \"ja_core_news_sm\",\n    \"ko\": \"ko_core_news_sm\",\n}\n\n# üõë Load Stanza models for regional languages\nstanza_models = {\n    \"hi\": \"hi\",\n    \"ta\": \"ta\",\n    \"te\": \"te\",\n    \"mr\": \"mr\",\n    \"ur\": \"ur\",\n}\n\n# üîπ Download and Load spaCy Models\nnlp_spacy = {}\nfor lang, model in spacy_models.items():\n    try:\n        nlp_spacy[lang] = spacy.load(f\"{SPACY_PATH}/{model}\")\n    except:\n        print(f\"‚è≥ Downloading spaCy model: {model}\")\n        subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", model])\n        nlp_spacy[lang] = spacy.load(model)\n        nlp_spacy[lang].to_disk(f\"{SPACY_PATH}/{model}\")\n\n# üîπ Download and Load Stanza Models\nfor lang in stanza_models.values():\n    stanza.download(lang, model_dir=STANZA_PATH)\n\nnlp_stanza = {lang: stanza.Pipeline(lang, dir=STANZA_PATH) for lang in stanza_models.keys()}\n\n# üîé Language Detection Function\ndef detect_language(text):\n    \"\"\"Detects the language of the text using langdetect.\"\"\"\n    try:\n        return langdetect.detect(text)\n    except:\n        return \"en\"\n\n# ‚ú® Preprocessing Function\ndef preprocess_text(text):\n    \"\"\"Automatically preprocesses text based on detected language.\"\"\"\n    lang = detect_language(text)\n\n    if lang in nlp_spacy:\n        doc = nlp_spacy[lang](text)\n        clean_tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n    elif lang in nlp_stanza:\n        doc = nlp_stanza[lang](text)\n        clean_tokens = [word.lemma for sent in doc.sentences for word in sent.words if word.text.isalpha()]\n    else:\n        return text.lower()  # Default to lowercased text if no model is available\n\n    return \" \".join(clean_tokens).lower()\n\n# üìù Example Usage\ntexts = [\n    \"NASA is launching a new mission to Mars!\",\n    \"‡§®‡§æ‡§∏‡§æ ‡§Æ‡§Ç‡§ó‡§≤ ‡§ó‡•ç‡§∞‡§π ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§Æ‡§ø‡§∂‡§® ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\",\n    \"‡Æ®‡Ææ‡Æö‡Ææ ‡Æö‡ØÜ‡Æµ‡Øç‡Æµ‡Ææ‡ÆØ‡Øç ‡Æï‡Æø‡Æ∞‡Æï‡Æ§‡Øç‡Æ§‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡Æí‡Æ∞‡ØÅ ‡Æ™‡ØÅ‡Æ§‡Æø‡ÆØ ‡Æ§‡Æø‡Æü‡Øç‡Æü‡Æ§‡Øç‡Æ§‡Øà ‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡Æ§‡Øç‡Æ§‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ!\",\n    \"El lanzamiento de la misi√≥n est√° programado para 2025.\",\n    \"La missione √® programmata per il 2025.\",\n    \"ŒúŒπŒ± ŒΩŒ≠Œ± Œ±œÄŒøœÉœÑŒøŒªŒÆ Œ∏Œ± ŒæŒµŒ∫ŒπŒΩŒÆœÉŒµŒπ œÑŒø 2025.\",\n]\n\nfor text in texts:\n    print(f\"Original: {text}\")\n    print(f\"Preprocessed: {preprocess_text(text)}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:56:36.110862Z","iopub.execute_input":"2025-03-17T12:56:36.111094Z","iopub.status.idle":"2025-03-17T12:57:38.686479Z","shell.execute_reply.started":"2025-03-17T12:56:36.111072Z","shell.execute_reply":"2025-03-17T12:57:38.685647Z"}},"outputs":[{"name":"stdout","text":"‚è≥ Downloading spaCy model: en_core_web_sm\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7ba015f5f1a40d08895e41a41f43e03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26b00af2b7cb4b0f91f92e07902b3dfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ba90cf4913c4c0cac53c5e2126b1eac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12122c719c624f66af1e915b0b113a92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc2c62fc5764e5fb27b3652d3159177"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b2838353bb946b084dc18b577eb48a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4f6338304744f8c805d3b9632cf57c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9570df5661243f9a91bf7e35a2cca87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36053aa7fc1a49319d4794d429f627d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aa76f2140d54010a3ec43c66585f3f6"}},"metadata":{}},{"name":"stdout","text":"Original: NASA is launching a new mission to Mars!\nPreprocessed: nasa launch new mission mars\n\nOriginal: ‡§®‡§æ‡§∏‡§æ ‡§Æ‡§Ç‡§ó‡§≤ ‡§ó‡•ç‡§∞‡§π ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§Æ‡§ø‡§∂‡§® ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\nPreprocessed: ‡§è‡§ï ‡§ï‡§∞‡§®‡§æ\n\nOriginal: ‡Æ®‡Ææ‡Æö‡Ææ ‡Æö‡ØÜ‡Æµ‡Øç‡Æµ‡Ææ‡ÆØ‡Øç ‡Æï‡Æø‡Æ∞‡Æï‡Æ§‡Øç‡Æ§‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡Æí‡Æ∞‡ØÅ ‡Æ™‡ØÅ‡Æ§‡Æø‡ÆØ ‡Æ§‡Æø‡Æü‡Øç‡Æü‡Æ§‡Øç‡Æ§‡Øà ‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡Æ§‡Øç‡Æ§‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ!\nPreprocessed: \n\nOriginal: El lanzamiento de la misi√≥n est√° programado para 2025.\nPreprocessed: lanzamiento misi√≥n programado\n\nOriginal: La missione √® programmata per il 2025.\nPreprocessed: missione programmare\n\nOriginal: ŒúŒπŒ± ŒΩŒ≠Œ± Œ±œÄŒøœÉœÑŒøŒªŒÆ Œ∏Œ± ŒæŒµŒ∫ŒπŒΩŒÆœÉŒµŒπ œÑŒø 2025.\nPreprocessed: ŒΩŒ≠ŒøœÇ Œ±œÄŒøœÉœÑŒøŒªŒÆ ŒæŒµŒ∫ŒπŒΩœé\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport spacy\nimport stanza\nimport torch\nfrom transformers import BartForConditionalGeneration, BartTokenizer\nfrom concurrent.futures import ThreadPoolExecutor\nimport re\nimport subprocess\nimport os\n\n# üîÑ Install missing libraries (if needed)\ntry:\n    import stanza\nexcept ModuleNotFoundError:\n    subprocess.run([\"pip\", \"install\", \"stanza\"])\n\ntry:\n    import spacy\nexcept ModuleNotFoundError:\n    subprocess.run([\"pip\", \"install\", \"spacy\"])\n\n# üìÇ Paths for saving models in Kaggle\nSPACY_PATH = \"/kaggle/working/spacy_models\"\nSTANZA_PATH = \"/kaggle/working/stanza_resources\"\nos.makedirs(SPACY_PATH, exist_ok=True)\nos.makedirs(STANZA_PATH, exist_ok=True)\n\n# üåç Load language models\ntry:\n    nlp_spacy = spacy.load(f\"{SPACY_PATH}/en_core_web_sm\")\nexcept:\n    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n    nlp_spacy = spacy.load(\"en_core_web_sm\")\n    nlp_spacy.to_disk(f\"{SPACY_PATH}/en_core_web_sm\")\n\nstanza.download(\"en\", model_dir=STANZA_PATH)\nnlp_stanza = stanza.Pipeline(lang='en', processors='tokenize,lemma', batch_size=64, use_gpu=True, dir=STANZA_PATH)\n\n# üîπ Load BART model and tokenizer from Hugging Face (no local path required in Kaggle)\ntry:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n    model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n    print(\"‚úÖ BART model loaded successfully!\")\nexcept Exception as e:\n    print(f\"‚ùå Error loading BART model: {e}\")\n    exit()\n\n# üßπ Text cleaning function\ndef clean_text(text):\n    text = str(text).lower().strip()\n    text = re.sub(r'http\\S+|www.\\S+', '', text)  # Remove URLs\n    text = re.sub(r'\\s+', ' ', text)             # Remove extra spaces\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)   # Remove special characters\n    return text\n\n# üîÑ Tokenization and lemmatization using SpaCy\ndef preprocess_spacy(text):\n    try:\n        doc = nlp_spacy(text)\n        return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n    except Exception:\n        return text  # Fallback if processing fails\n\n# üîÑ Tokenization and lemmatization using Stanza\ndef preprocess_stanza(text):\n    try:\n        doc = nlp_stanza(text)\n        return \" \".join([word.lemma for sentence in doc.sentences for word in sentence.words])\n    except Exception:\n        return text  # Fallback if processing fails\n\n# üîπ Batch Abstractive summarization using BART\ndef abstractive_summarization_batch(texts, max_len=130):\n    try:\n        inputs = tokenizer(texts, return_tensors=\"pt\", max_length=1024, truncation=True, padding=True).to(device)\n        summary_ids = model.generate(inputs[\"input_ids\"], max_length=max_len, num_beams=4, early_stopping=True)\n        return [tokenizer.decode(s, skip_special_tokens=True) for s in summary_ids]\n    except Exception:\n        return texts  # Fallback if summarization fails\n\n# üîÑ Batch processing with parallel execution\ndef process_chunk(chunk):\n    chunk.columns = chunk.columns.str.strip()\n\n    # üîé Updated text column identification\n    if 'Text' not in chunk.columns:\n        print(f\"‚ùå No suitable text column found in chunk. Skipping...\")\n        return pd.DataFrame()\n\n    print(f\"‚úÖ Processing chunk with column 'Text'\")\n\n    with ThreadPoolExecutor(max_workers=8) as executor:\n        chunk['cleaned_text'] = list(executor.map(clean_text, chunk['Text']))\n        chunk['spacy_text'] = list(executor.map(preprocess_spacy, chunk['cleaned_text']))\n        chunk['stanza_text'] = list(executor.map(preprocess_stanza, chunk['cleaned_text']))\n        chunk['summary'] = abstractive_summarization_batch(chunk['cleaned_text'].tolist())\n\n    return chunk\n\n# üîπ Load and process dataset in chunks\nchunk_size = 1000\noutput_path = '/kaggle/working/preprocessed_train.csv'\n\ntry:\n    for idx, chunk in enumerate(pd.read_csv('/kaggle/input/summary/BBCarticles.csv', encoding='windows-1252', chunksize=chunk_size)):\n        processed_chunk = process_chunk(chunk)\n\n        if not processed_chunk.empty:\n            processed_chunk.to_csv(output_path, mode='a', index=False, header=not idx, float_format='%.3f')\n            print(f\"‚úÖ Chunk {idx + 1} saved successfully.\")\n\n    print(f\"‚úÖ Preprocessing completed successfully! Data saved to: {output_path}\")\n\nexcept FileNotFoundError:\n    print(\"‚ùå Error: 'BBCarticles.csv' not found.\")\nexcept Exception as e:\n    print(f\"‚ùå Unexpected Error: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T12:57:38.687524Z","iopub.execute_input":"2025-03-17T12:57:38.687879Z","iopub.status.idle":"2025-03-17T13:05:03.577863Z","shell.execute_reply.started":"2025-03-17T12:57:38.687853Z","shell.execute_reply":"2025-03-17T13:05:03.577005Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d4d892616ba41c4aabbdb6fb1ed4805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"452a74e1bd524353935e772473b3271b"}},"metadata":{}},{"name":"stdout","text":"‚úÖ BART model loaded successfully!\n‚úÖ Processing chunk with column 'Text'\n‚úÖ Chunk 1 saved successfully.\n‚úÖ Processing chunk with column 'Text'\n‚úÖ Chunk 2 saved successfully.\n‚úÖ Processing chunk with column 'Text'\n‚úÖ Chunk 3 saved successfully.\n‚úÖ Preprocessing completed successfully! Data saved to: /kaggle/working/preprocessed_train.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:05:03.578800Z","iopub.execute_input":"2025-03-17T13:05:03.579121Z","iopub.status.idle":"2025-03-17T13:05:07.271922Z","shell.execute_reply.started":"2025-03-17T13:05:03.579088Z","shell.execute_reply":"2025-03-17T13:05:07.270855Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport torch\nimport spacy\nimport stanza\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nfrom transformers import BartForConditionalGeneration, BartTokenizer\nfrom concurrent.futures import ThreadPoolExecutor\nfrom datasets import load_dataset\nimport csv\nimport glob  # For detecting completed chunks\n\n# ‚úÖ Load Language Models\nnlp_spacy = spacy.load(\"en_core_web_sm\")\nnlp_stanza = stanza.Pipeline(lang='en', processors='tokenize,lemma', batch_size=32, use_gpu=True)\n\n# ‚úÖ Preprocessing Functions\ndef clean_text(text):\n    return \" \".join([token.lemma_ for token in nlp_spacy(text) if not token.is_stop and not token.is_punct])\n\ndef preprocess_stanza(text):\n    doc = nlp_stanza(text)\n    return \" \".join([word.lemma for sentence in doc.sentences for word in sentence.words])\n\ndef preprocess_data(examples):\n    cleaned_texts = preprocess_in_parallel(examples['text'], clean_text)\n    model_inputs = tokenizer(\n        cleaned_texts, \n        max_length=256,   \n        truncation=True, \n        padding='max_length'\n    )\n    labels = tokenizer(\n        examples['summary'],\n        max_length=130,\n        truncation=True,\n        padding='max_length'\n    ).input_ids\n\n    model_inputs['labels'] = [\n        [-100 if token == tokenizer.pad_token_id else token for token in label]\n        for label in labels\n    ]\n    return model_inputs\n\n# ‚úÖ Parallel Processing for Faster Text Cleaning\ndef preprocess_in_parallel(text_list, function, max_workers=8):\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        return list(executor.map(function, text_list))\n\n# ‚úÖ Save Preprocessed Data as CSV\ndef save_dataset_as_csv(dataset, lang_code, chunk_number):\n    output_path = f\"/kaggle/working/{lang_code}_chunk_{chunk_number}.csv\"\n    dataset.to_pandas().to_csv(output_path, index=False)\n    print(f\"‚úÖ Saved: {output_path}\")\n\n# ‚úÖ Track Completed Chunks\ndef get_completed_chunks(lang_code):\n    existing_files = glob.glob(f\"/kaggle/working/{lang_code}_chunk_*.csv\")\n    completed_chunks = [int(file.split('_')[-1].split('.')[0]) for file in existing_files]\n    return max(completed_chunks) + 1 if completed_chunks else 0\n\n# ‚úÖ Chunk-Based Processing with Resume Functionality\ndef process_and_save_in_chunks(dataset, chunk_size=2000, lang_code=\"english\"):\n    total_samples = len(dataset['train'])\n    start_chunk = get_completed_chunks(lang_code)\n\n    for start_idx in range(start_chunk * chunk_size, total_samples, chunk_size):\n        end_idx = min(start_idx + chunk_size, total_samples)\n        dataset_chunk = dataset['train'].select(range(start_idx, end_idx))\n\n        processed_chunk = dataset_chunk.map(preprocess_data, batched=True)\n        save_dataset_as_csv(processed_chunk, lang_code, chunk_number=start_idx // chunk_size)\n\n        print(f\"‚úÖ Processed and saved chunk {start_idx // chunk_size + 1} for {lang_code}\")\n\n# ‚úÖ Main Code Execution\ntokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n\nlanguages = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"spanish\", \"french\", \"german\", \"chinese\", \"japanese\"]\n\n# ‚úÖ Load XLSum for Other Languages\nfor lang in languages:\n    try:\n        dataset = load_dataset(\"csebuetnlp/xlsum\", lang)\n        process_and_save_in_chunks(dataset, lang_code=lang)\n        print(f\"‚úÖ Successfully processed data for: {lang}\")\n    except Exception as e:\n        print(f\"‚ùå Failed to load data for {lang}: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:05:07.273061Z","iopub.execute_input":"2025-03-17T13:05:07.273302Z","iopub.status.idle":"2025-03-17T17:29:09.855825Z","shell.execute_reply.started":"2025-03-17T13:05:07.273279Z","shell.execute_reply":"2025-03-17T17:29:09.854908Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49cf20e678f44b69976f5f9e87410cf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/tokenize/combined.pt:   0%|   ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dc24bcd10824fc7a657a3b648fe8ebe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/mwt/combined.pt:   0%|        ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dded7a3e60234e99b53c11dbeb54a4bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/lemma/combined_nocharlm.pt:   ‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63845b4b7aa44a23a7f4b6c78ec4b385"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/14.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac28cf5436e147cba5f5085da9462b8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"xlsum.py:   0%|          | 0.00/4.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb363043d5c54665ae6977fce30fdda7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/187M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ecda8a33772474bbbc332824d562c11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0001.parquet:   0%|          | 0.00/19.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8e07d7ca53746cdb0c973645d3a94a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/21.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5443fbb6b57c4418899ed1a2a8efa01a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/21.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eca1e17114664bf1a6e4683638322671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/70778 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9e27f879e9f43398af0f0b4c8e67bd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/8847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29b99540fbc04d14a8dbd2efb11bb2f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/8847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f7a0763104547b3bdc69f0979b78ced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a94cede87444c09b681812993404d79"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_0.csv\n‚úÖ Processed and saved chunk 1 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecce9b5d785a46e2900a238363cb490f"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_1.csv\n‚úÖ Processed and saved chunk 2 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"987e961a7dcd4c0d84b3f80ebf1d99cc"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_2.csv\n‚úÖ Processed and saved chunk 3 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de20ed956da14ca2b3092553398abf1c"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_3.csv\n‚úÖ Processed and saved chunk 4 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455a9052e22c4783b7fdbd316bade2a4"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_4.csv\n‚úÖ Processed and saved chunk 5 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d53f017ab854df5a1a514fec7016203"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_5.csv\n‚úÖ Processed and saved chunk 6 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e42401d242ce4bc3aef055161df03303"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_6.csv\n‚úÖ Processed and saved chunk 7 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2f78ba0961843999c8a72f9c36cdcb3"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_7.csv\n‚úÖ Processed and saved chunk 8 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16a016aa27e04571a7e92137e6477134"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_8.csv\n‚úÖ Processed and saved chunk 9 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10cfdc1f93c43a29583384ff9750a7c"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_9.csv\n‚úÖ Processed and saved chunk 10 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb5a5160bf7d426fa832d67731976ccc"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_10.csv\n‚úÖ Processed and saved chunk 11 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df2faf89fd894c19abf69ec7fbe16b1d"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_11.csv\n‚úÖ Processed and saved chunk 12 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e97bff0d154d40e38dd2e33786f271cc"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_12.csv\n‚úÖ Processed and saved chunk 13 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a2033431cc548069c12e31ead4ce85a"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_13.csv\n‚úÖ Processed and saved chunk 14 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a43838e4cf446eb2ab09e154a40a8c"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_14.csv\n‚úÖ Processed and saved chunk 15 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6417ccc84f2744a29e982f71cdf508ff"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_15.csv\n‚úÖ Processed and saved chunk 16 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25fe53f3fb7941a6b94acf19dc6f78cf"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_16.csv\n‚úÖ Processed and saved chunk 17 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11c14aea4be645eb8484e639d803e1da"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_17.csv\n‚úÖ Processed and saved chunk 18 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27896d0ab2284254a0fb0939d040d228"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_18.csv\n‚úÖ Processed and saved chunk 19 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"722449db5def450c9c4919648d1a7eb4"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_19.csv\n‚úÖ Processed and saved chunk 20 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72dbd7298e6c4ceba0c1d83d974b30f2"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_20.csv\n‚úÖ Processed and saved chunk 21 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4cf7a697bf148349da3ec0515cb64df"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_21.csv\n‚úÖ Processed and saved chunk 22 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c84de9e94a504904bf114d337cc9a6a5"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_22.csv\n‚úÖ Processed and saved chunk 23 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e704fafbdcc44629a514f425dad96cd"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_23.csv\n‚úÖ Processed and saved chunk 24 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"428f6289c614478498756abc2bbed8d0"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_24.csv\n‚úÖ Processed and saved chunk 25 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df5061a03aff4eb28c8c628a8571a231"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_25.csv\n‚úÖ Processed and saved chunk 26 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83728962fd634737996aed0384432e1e"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_26.csv\n‚úÖ Processed and saved chunk 27 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25d2f82030c04db0882af254c4210e19"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_27.csv\n‚úÖ Processed and saved chunk 28 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"593e52f409d74f1588919575d366e4c7"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_28.csv\n‚úÖ Processed and saved chunk 29 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6e97ed4c7249cd9bb79eb0a62cd83d"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_29.csv\n‚úÖ Processed and saved chunk 30 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f282825487b040a2b326a487a3ccaf8a"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_30.csv\n‚úÖ Processed and saved chunk 31 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a265807893074daa801c3ccaea50e880"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_31.csv\n‚úÖ Processed and saved chunk 32 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d3728b1af474c789814651ce41ef1aa"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_32.csv\n‚úÖ Processed and saved chunk 33 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b271fd403454de38ddcc186271b142a"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_33.csv\n‚úÖ Processed and saved chunk 34 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"370f39417ec84cbcbc0c1e68d7ade23d"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_34.csv\n‚úÖ Processed and saved chunk 35 for hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/778 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92bf1f06ea024fbdb61d12e157681e30"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/hindi_chunk_35.csv\n‚úÖ Processed and saved chunk 36 for hindi\n‚úÖ Successfully processed data for: hindi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/61.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134062ce5b564ed8be09719c62ca8a8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/6.97M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9970c692bd614d27a353e54f5e8682ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/7.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4063d0aac12144429f7c4d12d07fa178"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16222 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f02b9b2c75c4db2b3285bc9bc8a5152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2027 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41633ef047b24f788dfe084d228d512e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2027 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e7f6a212ef4dd2a4730c6737486463"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b084cc22f8ff4f0daf80068187e7787f"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/tamil_chunk_0.csv\n‚úÖ Processed and saved chunk 1 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b9d06027c874a6e946842792a9addff"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/tamil_chunk_1.csv\n‚úÖ Processed and saved chunk 2 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d4be8f11c7e4af08229b40110fc2242"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/tamil_chunk_2.csv\n‚úÖ Processed and saved chunk 3 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87186f20f191454b9dccdb21eebe61f9"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/tamil_chunk_3.csv\n‚úÖ Processed and saved chunk 4 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a07d4edd1be4134b070ede7104d1f40"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/tamil_chunk_4.csv\n‚úÖ Processed and saved chunk 5 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6ba6748ffa2487abcf1ef3960862b80"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/tamil_chunk_5.csv\n‚úÖ Processed and saved chunk 6 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"460c05a4185542dca8160291cb6355d2"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/tamil_chunk_6.csv\n‚úÖ Processed and saved chunk 7 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a735e57ff0f1498fa67341da277161b6"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/tamil_chunk_7.csv\n‚úÖ Processed and saved chunk 8 for tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/222 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c17a1150934491f9b59363872160bc8"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/tamil_chunk_8.csv\n‚úÖ Processed and saved chunk 9 for tamil\n‚úÖ Successfully processed data for: tamil\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/46.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db36e2b5b1d643abb06e5f5178e1a4f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/5.01M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5430ab529a2842a0b964a89d8cbc95b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/4.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fee0aa2fcf8f4b70af4caee0cf85f031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10421 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f959728a425547d1910ff59c3840c07c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1302 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4539fb617624f6e8974536fe721148b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1302 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04c4bd7962b14967956d00519eba5a64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2d7474f133745a9a6d70ba46d0f34f7"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/telugu_chunk_0.csv\n‚úÖ Processed and saved chunk 1 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8f185151b2d45e18aac349a34d56ad1"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/telugu_chunk_1.csv\n‚úÖ Processed and saved chunk 2 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8c320e712b547ff8ae4194be5fda8e3"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/telugu_chunk_2.csv\n‚úÖ Processed and saved chunk 3 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b44e6477037417682845b14fe931725"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/telugu_chunk_3.csv\n‚úÖ Processed and saved chunk 4 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e5641712d084152a4aa2b26e0a77820"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/telugu_chunk_4.csv\n‚úÖ Processed and saved chunk 5 for telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/421 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e93d6dc1ad8c48c6a5dbd53e925937a2"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/telugu_chunk_5.csv\n‚úÖ Processed and saved chunk 6 for telugu\n‚úÖ Successfully processed data for: telugu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/50.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f56f35fe906f49ea9f768375f7f13d3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/5.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ebb973fb51434e93f28ab51215b150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f8bf0425a4944aaaf5bf57fe6ae174a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10903 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ee9312e5284c939b3d1c3362313427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8221ee1ca649479e9b737ecad90847"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38e9c423e3e04d88967467fc66589404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b3311058aa942c98329df372b55cd50"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/marathi_chunk_0.csv\n‚úÖ Processed and saved chunk 1 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0238cf75af2946a4930043bba3287d1c"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/marathi_chunk_1.csv\n‚úÖ Processed and saved chunk 2 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9773d41f9c4140e48b5479a78fa38006"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/marathi_chunk_2.csv\n‚úÖ Processed and saved chunk 3 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"088c6eb545484608ab1e6e172de573b4"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/marathi_chunk_3.csv\n‚úÖ Processed and saved chunk 4 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2ab31aaa2ac44c28a383bd32166396b"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/marathi_chunk_4.csv\n‚úÖ Processed and saved chunk 5 for marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/903 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"841297df36ac44208a04e37203b43669"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/marathi_chunk_5.csv\n‚úÖ Processed and saved chunk 6 for marathi\n‚úÖ Successfully processed data for: marathi\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/125M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1063be3a8b7645a2b927ca906a62d97e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e35d669f71f74f84b06bbfdb287cdff9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f5bde6deeb45ffb580dd1e98f898fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/38110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cee9dbaf7d5d44a086ea7b8214368f51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4763 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17427381367f471e9d23d1cbdb7e1379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/4763 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41b0982b61c440b195afb70c426516e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf52a770b5424ff1872e6243a932d92b"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_0.csv\n‚úÖ Processed and saved chunk 1 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2218f6619f6a4c72a091d912cbe57df3"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_1.csv\n‚úÖ Processed and saved chunk 2 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8432e5bb58441f5958365cfbd3b8bfe"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_2.csv\n‚úÖ Processed and saved chunk 3 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fef643ce68914ae3acd6beef76118461"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_3.csv\n‚úÖ Processed and saved chunk 4 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0caf3e5bb2f4491080a220737dca69c5"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_4.csv\n‚úÖ Processed and saved chunk 5 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11cdffa706a84e77ab6c72a496ad6a24"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_5.csv\n‚úÖ Processed and saved chunk 6 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01f51065f5474fde9b8ce4a6a5f2fcd1"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_6.csv\n‚úÖ Processed and saved chunk 7 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9fd26fa506744ecab4f2700657dae28"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_7.csv\n‚úÖ Processed and saved chunk 8 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"662a109a5bb4441a84f45a11df62adbe"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_8.csv\n‚úÖ Processed and saved chunk 9 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4772ad375d7942d3bccbc81a447d2025"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_9.csv\n‚úÖ Processed and saved chunk 10 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfef7cd0ff3e42559385980880a0dc68"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_10.csv\n‚úÖ Processed and saved chunk 11 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba0e26732e51472195f8c0802f41dfe3"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_11.csv\n‚úÖ Processed and saved chunk 12 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f591d26a35c84b00817d429ce2d9b092"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_12.csv\n‚úÖ Processed and saved chunk 13 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b239a96b3e944b2291c64a113b15d9f6"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_13.csv\n‚úÖ Processed and saved chunk 14 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6bbf0ca4b3844f6991f633a8628930d"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_14.csv\n‚úÖ Processed and saved chunk 15 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d34769ba9970448eb17c8493b430a2fb"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_15.csv\n‚úÖ Processed and saved chunk 16 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb5d0b4aa98c4078a4daa17ec8365df2"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_16.csv\n‚úÖ Processed and saved chunk 17 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae3e573880d3469fb80e587965c17adf"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_17.csv\n‚úÖ Processed and saved chunk 18 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e009f7d058324b62a624c68ca43d2cd6"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_18.csv\n‚úÖ Processed and saved chunk 19 for spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"860bac847a5a4ba0b25478e2d2b4893a"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/spanish_chunk_19.csv\n‚úÖ Processed and saved chunk 20 for spanish\n‚úÖ Successfully processed data for: spanish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf2caa420a642ebac7ed23cd10bdd1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/1.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f768df709038461a8690aeefb91dea33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/1.74M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e94b7967d7c44d6be4fc5a0cd159611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/8697 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17ce7be5afb64fab98fa7ed04a592ba1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1086 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25973f112dc9401580f71ae842a03be0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1086 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b11a19f3b967441680b643fb02df327e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aa5cc209bbd4ffe9ef02ed3d5012d6c"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/french_chunk_0.csv\n‚úÖ Processed and saved chunk 1 for french\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b9c8e6c7a5f4373a7096ce5412f861c"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/french_chunk_1.csv\n‚úÖ Processed and saved chunk 2 for french\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a94fd0a7e024955b3699cab22dbc275"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/french_chunk_2.csv\n‚úÖ Processed and saved chunk 3 for french\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bced9f8550e475690b5e0b3d6d8876e"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/french_chunk_3.csv\n‚úÖ Processed and saved chunk 4 for french\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/697 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16ce90df4d304f67b7b3ed483657e37d"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/french_chunk_4.csv\n‚úÖ Processed and saved chunk 5 for french\n‚úÖ Successfully processed data for: french\n‚ùå Failed to load data for german: BuilderConfig 'german' not found. Available: ['amharic', 'arabic', 'azerbaijani', 'bengali', 'burmese', 'chinese_simplified', 'chinese_traditional', 'english', 'french', 'gujarati', 'hausa', 'hindi', 'igbo', 'indonesian', 'japanese', 'kirundi', 'korean', 'kyrgyz', 'marathi', 'nepali', 'oromo', 'pashto', 'persian', 'pidgin', 'portuguese', 'punjabi', 'russian', 'scottish_gaelic', 'serbian_cyrillic', 'serbian_latin', 'sinhala', 'somali', 'spanish', 'swahili', 'tamil', 'telugu', 'thai', 'tigrinya', 'turkish', 'ukrainian', 'urdu', 'uzbek', 'vietnamese', 'welsh', 'yoruba']\n‚ùå Failed to load data for chinese: BuilderConfig 'chinese' not found. Available: ['amharic', 'arabic', 'azerbaijani', 'bengali', 'burmese', 'chinese_simplified', 'chinese_traditional', 'english', 'french', 'gujarati', 'hausa', 'hindi', 'igbo', 'indonesian', 'japanese', 'kirundi', 'korean', 'kyrgyz', 'marathi', 'nepali', 'oromo', 'pashto', 'persian', 'pidgin', 'portuguese', 'punjabi', 'russian', 'scottish_gaelic', 'serbian_cyrillic', 'serbian_latin', 'sinhala', 'somali', 'spanish', 'swahili', 'tamil', 'telugu', 'thai', 'tigrinya', 'turkish', 'ukrainian', 'urdu', 'uzbek', 'vietnamese', 'welsh', 'yoruba']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/21.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68f87ce3ddae46c0a5d118d1fd5f06ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/2.54M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86dcded8ab684f2fb6b716b6d7e83fd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f67f52b839c43ac96e733ed87aea163"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a55737972eb5477f98614adaa9ef2e7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/889 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"def8beb0dd744e28ba84a7d1fb94e6eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/889 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af440db40a0f4e938e2e1b04ed22473a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4b44da2f4af4040a7b3a84141496c74"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/japanese_chunk_0.csv\n‚úÖ Processed and saved chunk 1 for japanese\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8584d6990a4b82852cf1c6254e5779"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/japanese_chunk_1.csv\n‚úÖ Processed and saved chunk 2 for japanese\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b562f0af13894c22aa1ebc526e7bf9b0"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/japanese_chunk_2.csv\n‚úÖ Processed and saved chunk 3 for japanese\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dce107653084e2dac05aa097be085bb"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved: /kaggle/working/japanese_chunk_3.csv\n‚úÖ Processed and saved chunk 4 for japanese\n‚úÖ Successfully processed data for: japanese\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BartForConditionalGeneration, BartTokenizer\nfrom transformers import AdamW, get_scheduler\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\n\n# ‚úÖ Custom Dataset Class\nclass SummarizationDataset(Dataset):\n    def __init__(self, file_path, tokenizer, max_input_len=256, max_output_len=130):\n        self.data = pd.read_csv(file_path).dropna()\n        self.tokenizer = tokenizer\n        self.max_input_len = max_input_len\n        self.max_output_len = max_output_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = str(self.data.iloc[idx]['text']).strip()\n        summary = str(self.data.iloc[idx]['summary']).strip()\n\n        inputs = self.tokenizer(text, max_length=self.max_input_len, padding='max_length', truncation=True, return_tensors='pt')\n        labels = self.tokenizer(summary, max_length=self.max_output_len, padding='max_length', truncation=True, return_tensors='pt').input_ids\n\n        labels[labels == self.tokenizer.pad_token_id] = -100\n\n        return {\n            'input_ids': inputs['input_ids'].squeeze(0),\n            'attention_mask': inputs['attention_mask'].squeeze(0),\n            'labels': labels.squeeze(0)\n        }\n\n# ‚úÖ DataLoader Function\ndef get_data_loaders(batch_size=8):\n    train_loaders, val_loaders = [], []\n    languages = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"spanish\", \"french\", \"japanese\"]\n\n    for lang in languages:\n        train_file = f\"/kaggle/working/{lang}_chunk_0.csv\"\n        val_file = f\"/kaggle/working/{lang}_chunk_1.csv\"\n\n        train_dataset = SummarizationDataset(train_file, tokenizer)\n        val_dataset = SummarizationDataset(val_file, tokenizer)\n\n        train_loaders.append(DataLoader(train_dataset, batch_size=batch_size, shuffle=True))\n        val_loaders.append(DataLoader(val_dataset, batch_size=batch_size))\n\n    return train_loaders, val_loaders\n\n# ‚úÖ Training Loop\ndef train_model(model, train_loaders, val_loaders, epochs=3, lr=3e-5):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n\n    optimizer = AdamW(model.parameters(), lr=lr)\n    lr_scheduler = get_scheduler(\n        name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=epochs * len(train_loaders[0])\n    )\n\n    loss_fn = nn.CrossEntropyLoss()\n\n    best_val_loss = float('inf')\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss, correct_train, total_train = 0, 0, 0\n\n        for train_loader in train_loaders:\n            for batch in tqdm(train_loader, desc=f\"üöÇ Training Epoch {epoch + 1}\"):\n                optimizer.zero_grad()\n\n                inputs = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n\n                outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)\n                loss = outputs.loss\n                loss.backward()\n                optimizer.step()\n                lr_scheduler.step()\n\n                total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loaders[0])\n        print(f\"‚úÖ Epoch {epoch + 1}/{epochs}, Avg Training Loss: {avg_loss:.4f}\")\n\n        # Validation Step\n        model.eval()\n        val_loss = 0\n\n        with torch.no_grad():\n            for val_loader in val_loaders:\n                for batch in tqdm(val_loader, desc=\"üîé Validating\"):\n                    inputs = batch['input_ids'].to(device)\n                    attention_mask = batch['attention_mask'].to(device)\n                    labels = batch['labels'].to(device)\n\n                    outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)\n                    val_loss += outputs.loss.item()\n\n        avg_val_loss = val_loss / len(val_loaders[0])\n        print(f\"üîπ Validation Loss: {avg_val_loss:.4f}\")\n\n        # Save Best Model\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            model.save_pretrained(\"./best_model\")\n            print(\"üíæ Model saved as 'best_model'\")\n\n# ‚úÖ Load Model and Tokenizer\ntokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\nmodel = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n\n# ‚úÖ Load Data and Train\ntrain_loaders, val_loaders = get_data_loaders(batch_size=8)\ntrain_model(model, train_loaders, val_loaders, epochs=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T20:24:44.248620Z","iopub.status.idle":"2025-03-17T20:24:44.248918Z","shell.execute_reply":"2025-03-17T20:24:44.248803Z"}},"outputs":[],"execution_count":null}]}